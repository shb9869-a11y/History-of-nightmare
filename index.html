<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover,user-scalable=no">
<title>History of Nightmare â€” ACT 1 (final, stripped)</title>
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<style>
Â  :root{
Â  Â  --frame: 40px; --ui-gap: 8px;
Â  Â  --fs-body: clamp(12px, 2.0vmin, 15px);
Â  Â  --fs-strong: clamp(14px, 2.6vmin, 18px);
Â  Â  --fs-small: clamp(11px, 1.7vmin, 13px);
Â  Â  --pad-line: clamp(4px, 0.9vmin, 8px);
Â  Â  --pad-btn-y: clamp(6px, 1.1vmin, 10px);
Â  Â  --pad-btn-x: clamp(10px, 1.8vmin, 20px);
Â  }
Â  html,body{margin:0;height:100%;background:#000;overflow:hidden}
Â  #view{width:100%;height:100%;display:block;position:fixed;left:0;top:0;z-index:0}
Â  .frameBox{position:fixed;left:var(--frame);top:var(--frame);right:var(--frame);bottom:var(--frame);border:1px solid #000;pointer-events:none;z-index:50}

Â  /* ì˜ì‚¬ ì˜ìƒ ë ˆì´ì–´ ìŠ¤íƒ€ì¼ (Z-index: 10) */
Â  #projectionVideo {
Â  Â  position: fixed;
Â  Â  inset: 0;
Â  Â  width: 100%;
Â  Â  height: 100%;
Â  Â  object-fit: cover;
Â  Â  z-index: 10; /* ì¹´ë©”ë¼ ìº”ë²„ìŠ¤(0)ì™€ UI(100) ì‚¬ì´ì— ë°°ì¹˜ */
Â  Â  opacity: 0; /* ì´ˆê¸°: ìˆ¨ê¹€ */
Â  Â  transition: opacity 0.5s ease; /* í˜ì´ë“œ íš¨ê³¼ */
Â  Â  pointer-events: none; /* í•˜ë‹¨ ì¹´ë©”ë¼ ì¡°ì‘ ë°©ì§€ */
Â  }

Â  .uiBtn{background:#000;color:#fff;border:1px solid #000;font-size:var(--fs-strong);
Â  Â  padding:var(--pad-btn-y) var(--pad-btn-x);font-family:"Courier New",monospace;white-space:nowrap;cursor:pointer;user-select:none}
Â  .uiBtn.small{font-size:var(--fs-small);padding:calc(var(--pad-btn-y)*0.6) calc(var(--pad-btn-x)*0.6)}

Â  .controls{position:fixed;right:calc(var(--frame) + var(--ui-gap));bottom:calc(var(--frame) + var(--ui-gap));
Â  Â  z-index:100;display:flex;gap:6px;align-items:center}
Â  .readout{min-width:48px;text-align:center;opacity:.9;font-family:"Courier New",monospace;font-size:var(--fs-small)}

Â  #overlay{position:fixed;inset:0;z-index:200;display:flex;align-items:center;justify-content:center;
Â  Â  padding:20px;font-family:"Courier New",monospace;color:#fff;background:transparent;pointer-events:none}
Â  #overlayContent{pointer-events:auto;line-height:1.7;font-size:var(--fs-body);
Â  Â  max-width:min(74ch, calc(100vw - (var(--frame)*2)));
Â  Â  max-height:calc(100vh - (var(--frame)*2));
Â  Â  overflow:hidden;text-align:left;transition:opacity .45s ease;opacity:1}
Â  .line{display:inline;background:#000;color:#fff;padding:calc(var(--pad-line)*0.8) var(--pad-line);
Â  Â  box-decoration-break:clone;-webkit-box-decoration-break:clone}
Â  .lineWrap{margin:6px 0}
Â  .hidden{opacity:0}
Â  @media (orientation:landscape){ :root{ --frame: 32px; } }
Â  .tip{opacity:.7;font-size:var(--fs-small);margin-top:8px}
</style>
</head>
<body>
Â  <canvas id="view"></canvas>
  Â  <video id="projectionVideo" autoplay playsinline muted></video>
  Â  <div class="frameBox" aria-hidden="true"></div>

Â  <div class="controls">
Â  Â  <button class="uiBtn small" id="zoomOut">â€“</button>
Â  Â  <div class="readout"><span id="zoomVal">1.0Ã—</span></div>
Â  Â  <button class="uiBtn small" id="zoomIn">+</button>
Â  </div>

Â  <div id="overlay">
Â  Â  <div id="overlayContent">
Â  Â  Â  <button id="welcomeBtn" class="uiBtn">Welcome to History of Nightmare</button>
Â  Â  Â  <div class="tip" id="sensorTip" style="display:none">ì„¼ì„œ ê¶Œí•œ í•„ìš”: ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ í—ˆìš© íŒì—…ì´ ëœ¹ë‹ˆë‹¤.</div>
Â  Â  </div>
Â  </div>

<script>
(()=>{

Â  /* ====== ê¸°ë³¸ ìº”ë²„ìŠ¤/ì¹´ë©”ë¼ ì„¤ì • (ì”ìƒ ì œê±°, í‘ë°±ë§Œ) ====== */
Â  const view=document.getElementById('view');
Â  const vctx=view.getContext('2d',{alpha:false});
Â  const PROC_SCALE=0.60, GLOBAL_ALPHA=0.9; // ì”ìƒ ì—†ìŒ(ë§¤ í”„ë ˆì„ í´ë¦¬ì–´)
Â  let ZOOM=1.0, ZOOM_MIN=0.5, ZOOM_MAX=3.0, ZOOM_STEP=0.1; // ì‹œì‘ ë°°ìœ¨ 1.0

Â  const zoomVal=document.getElementById('zoomVal');
Â  const clamp=(v,min,max)=>Math.max(min,Math.min(max,v));
Â  const updateZoom=()=>zoomVal.textContent=ZOOM.toFixed(1)+'Ã—';
Â  // fix: the clamp order for zoomIn was wrong; correct:
Â  document.getElementById('zoomIn').onclick=()=>{ZOOM=clamp(ZOOM+ZOOM_STEP,ZOOM_MIN,ZOOM_MAX);updateZoom();};
Â  document.getElementById('zoomOut').onclick=()=>{ZOOM=clamp(ZOOM-ZOOM_STEP,ZOOM_MIN,ZOOM_MAX);updateZoom();};
Â  updateZoom();

Â  const camVideo=document.createElement('video'); camVideo.autoplay=true; camVideo.playsInline=true; camVideo.muted=true;
Â  const proc=document.createElement('canvas'); const pctx=proc.getContext('2d',{willReadFrequently:true});

Â  function resizeAll(){
Â  Â  const dpr=window.devicePixelRatio||1;
Â  Â  const w=window.innerWidth,h=window.innerHeight;
Â  Â  view.width=w*dpr; view.height=h*dpr; vctx.setTransform(dpr,0,0,dpr,0,0);
Â  Â  const scale=(window.matchMedia('(orientation: landscape)').matches)? PROC_SCALE*0.9 : PROC_SCALE;
Â  Â  proc.width=Math.floor(w*scale); proc.height=Math.floor(h*scale);
Â  }
Â  resizeAll(); addEventListener('resize',()=>setTimeout(resizeAll,50));

Â  let _loopStarted=false;
Â  function ensureLoop(){ if(_loopStarted) return; _loopStarted=true; loop(); }

Â  function loop(){
Â  Â  requestAnimationFrame(loop);
Â  Â  const W=view.width/(window.devicePixelRatio||1);
Â  Â  const H=view.height/(window.devicePixelRatio||1);
Â  Â  const PW=proc.width, PH=proc.height;

Â  Â  // ì”ìƒ ì œê±°: ë§¤ í”„ë ˆì„ í´ë¦¬ì–´
Â  Â  pctx.clearRect(0,0,PW,PH);

Â  Â  if(camVideo.readyState>=2){
Â  Â  Â  const vw=camVideo.videoWidth, vh=camVideo.videoHeight;
Â  Â  Â  if(vw && vh){
Â  Â  Â  Â  const base=Math.max(PW/vw,PH/vh), sc=base*ZOOM;
Â  Â  Â  Â  const dw=vw*sc, dh=vh*sc, dx=(PW-dw)/2, dy=(PH-dh)/2;
Â  Â  Â  Â  pctx.globalAlpha=GLOBAL_ALPHA; pctx.drawImage(camVideo,dx,dy,dw,dh);
Â  Â  Â  Â  pctx.globalAlpha=1.0;
Â  Â  Â  Â  // í‘ë°± ë³€í™˜
Â  Â  Â  Â  const frame=pctx.getImageData(0,0,PW,PH); const d=frame.data;
Â  Â  Â  Â  for(let i=0;i<d.length;i+=4){
Â  Â  Â  Â  Â  const g=(0.299*d[i]+0.587*d[i+1]+0.114*d[i+2])|0;
Â  Â  Â  Â  Â  d[i]=d[i+1]=d[i+2]=g;
Â  Â  Â  Â  }
Â  Â  Â  Â  pctx.putImageData(frame,0,0);
Â  Â  Â  }
Â  Â  }
Â  Â  vctx.drawImage(proc,0,0,W,H);
Â  }

Â  async function attachCamera(){
Â  Â  const s=await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'},audio:false});
Â  Â  camVideo.srcObject=s; await camVideo.play().catch(()=>{});
Â  Â  return true;
Â  }

Â  function keepAlive(){
Â  Â  // ê¶Œí•œ í—ˆìš© í›„ íƒ­ ì¬ì§„ì… ì‹œ ë³´ì¥
Â  Â  if(audioCtx && audioCtx.state==='suspended'){ audioCtx.resume().catch(()=>{}); }
Â  }
Â  document.addEventListener('visibilitychange', keepAlive);
Â  window.addEventListener('focus', keepAlive);

Â  /* ====== ì˜¤ë””ì˜¤(ë§ˆì´í¬ + ê¸°ìš¸ê¸° ê¸°ë°˜ Pan/Vol) â€” BGM/ìº¡ì²˜ ì—†ìŒ ====== */
Â  let audioCtx=null;
Â  let mixBus=null, motionGain=null, masterGain=null;
Â  let panSetter=null;
Â  let micStream=null;

Â  const VOL_BASE=0.20, VOL_MAX_ADD=0.55;
Â  const SMOOTH_TC=0.08, CTRL_SMOOTH_ALPHA=0.12;
Â  const DEADZONE_VOL_DEG=5, DEADZONE_PAN_DEG=3, VOL_TILT_LIMIT=60, PAN_LIMIT_DEG=45;

Â  const MIC_HP=220, MIC_LOWSHELF_FREQ=200, MIC_LOWSHELF_GAIN=-12;
Â  const NOTCH_FREQ=300, NOTCH_Q=3.5;
Â  const COMP_THRESHOLD=-20, COMP_RATIO=3.5, COMP_ATTACK=0.006, COMP_RELEASE=0.12;
Â  const MAKEUP_GAIN=3.2;
Â  const MIC_WET=0.55, MIC_DRY=0.08;

Â  function initAudio(){
Â  Â  if(audioCtx) return;
Â  Â  audioCtx = new (window.AudioContext||window.webkitAudioContext)();

Â  Â  mixBus = audioCtx.createGain();
Â  Â  let panOutNode=null;

Â  Â  if (audioCtx.createStereoPanner){
Â  Â  Â  const sp=audioCtx.createStereoPanner();
Â  Â  Â  panSetter=(val)=>{ try{ sp.pan.setTargetAtTime(val, audioCtx.currentTime, 0.08);}catch{ sp.pan.value=val; } };
Â  Â  Â  mixBus.connect(sp); panOutNode=sp;
Â  Â  }else{
Â  Â  Â  const l=audioCtx.createGain(), r=audioCtx.createGain(), m=audioCtx.createChannelMerger(2);
Â  Â  Â  mixBus.connect(l); mixBus.connect(r);
Â  Â  Â  l.connect(m,0,0); r.connect(m,0,1);
Â  Â  Â  panSetter=(p)=>{
Â  Â  Â  Â  const x=Math.max(-1,Math.min(1,p||0)); const th=(x+1)*0.25*Math.PI;
Â  Â  Â  Â  const gL=Math.cos(th), gR=Math.sin(th);
Â  Â  Â  Â  try{ l.gain.setTargetAtTime(gL,audioCtx.currentTime,0.08); r.gain.setTargetAtTime(gR,audioCtx.currentTime,0.08); }
Â  Â  Â  Â  catch{ l.gain.value=gL; r.gain.value=gR; }
Â  Â  Â  };
Â  Â  Â  panOutNode=m;
Â  Â  }

Â  Â  motionGain = audioCtx.createGain(); motionGain.gain.value=VOL_BASE;
Â  Â  masterGain = audioCtx.createGain(); masterGain.gain.value=1.0;

Â  Â  panOutNode.connect(motionGain);
Â  Â  motionGain.connect(masterGain);
Â  Â  masterGain.connect(audioCtx.destination);
Â  }

Â  async function startMic(){
Â  Â  if(micStream) return;
Â  Â  const s=await navigator.mediaDevices.getUserMedia({
Â  Â  Â  audio:{ echoCancellation:false, noiseSuppression:true, autoGainControl:false },
Â  Â  Â  video:false
Â  Â  });
Â  Â  micStream=s;
Â  Â  const src=audioCtx.createMediaStreamSource(s);

Â  Â  // ì´í™íŠ¸ ì²´ì¸
Â  Â  const hpf=audioCtx.createBiquadFilter(); hpf.type='highpass'; hpf.frequency.value=MIC_HP; hpf.Q.value=0.707;
Â  Â  const lowshelf=audioCtx.createBiquadFilter(); lowshelf.type='lowshelf'; lowshelf.frequency.value=MIC_LOWSHELF_FREQ; lowshelf.gain.value=MIC_LOWSHELF_GAIN;
Â  Â  const notch=audioCtx.createBiquadFilter(); notch.type='notch'; notch.frequency.value=NOTCH_FREQ; notch.Q.value=NOTCH_Q;
Â  Â  const comp=audioCtx.createDynamicsCompressor();
Â  Â  comp.threshold.value=COMP_THRESHOLD; comp.ratio.value=COMP_RATIO;
Â  Â  comp.attack.value=COMP_ATTACK; comp.release.value=0.12;

Â  Â  const convolver=audioCtx.createConvolver(); convolver.buffer=makeIR(2.6,2.4);
Â  Â  const tapA=audioCtx.createDelay(); tapA.delayTime.value=0.11;
Â  Â  const tapB=audioCtx.createDelay(); tapB.delayTime.value=0.19;
Â  Â  const tapC=audioCtx.createDelay(); tapC.delayTime.value=0.27;
Â  Â  const fbA=audioCtx.createGain(); fbA.gain.value=0.28; tapA.connect(fbA).connect(tapA);
Â  Â  const fbB=audioCtx.createGain(); fbB.gain.value=0.22; tapB.connect(fbB).connect(tapB);
Â  Â  const fbC=audioCtx.createGain(); fbC.gain.value=0.18; tapC.connect(fbC).connect(tapC);
Â  Â  const wetSum=audioCtx.createGain();
Â  Â  convolver.connect(wetSum); tapA.connect(wetSum); tapB.connect(wetSum); tapC.connect(wetSum);

Â  Â  const wet=audioCtx.createGain(); wet.gain.value=MIC_WET;
Â  Â  const dry=audioCtx.createGain(); dry.gain.value=MIC_DRY;

Â  Â  const makeup=audioCtx.createGain(); makeup.gain.value=MAKEUP_GAIN;

Â  Â  const analyser=audioCtx.createAnalyser(); analyser.fftSize=512;
Â  Â  const gateGain=audioCtx.createGain(); gateGain.gain.value=0; gateLoop(analyser, gateGain);

Â  Â  // ê²°ì„ 
Â  Â  src.connect(hpf).connect(lowshelf).connect(notch).connect(comp);
Â  Â  comp.connect(analyser);
Â  Â  comp.connect(dry);

Â  Â  const wetSplit=audioCtx.createGain();
Â  Â  comp.connect(wetSplit);
Â  Â  wetSplit.connect(convolver); wetSplit.connect(tapA); wetSplit.connect(tapB); wetSplit.connect(tapC);
Â  Â  wetSum.connect(wet);

Â  Â  const micBus=audioCtx.createGain();
Â  Â  dry.connect(micBus); wet.connect(micBus);
Â  Â  micBus.connect(gateGain).connect(makeup).connect(mixBus);
Â  }

Â  function gateLoop(analyser, gate){
Â  Â  const buf=new Uint8Array(analyser.fftSize);
Â  Â  let open=false;
Â  Â  const GATE_OPEN_DB=-50, GATE_CLOSE_DB=-58, ATT=0.06, REL=0.25;
Â  Â  function step(){
Â  Â  Â  requestAnimationFrame(step);
Â  Â  Â  analyser.getByteTimeDomainData(buf);
Â  Â  Â  let sum=0; for(let i=0;i<buf.length;i++){ const v=(buf[i]-128)/128; sum+=v*v; }
Â  Â  Â  const rms=Math.sqrt(sum/buf.length);
Â  Â  Â  const db=20*Math.log10(Math.max(1e-6,rms));
Â  Â  Â  const now=audioCtx?.currentTime ?? 0;
Â  Â  Â  const shouldOpen = db>GATE_OPEN_DB || (open && db>GATE_CLOSE_DB);
Â  Â  Â  if(shouldOpen!==open){
Â  Â  Â  Â  open=shouldOpen;
Â  Â  Â  Â  try{ gate.gain.setTargetAtTime(open?1:0, now, open?ATT:REL); }
Â  Â  Â  Â  catch{ gate.gain.cancelScheduledValues(now); gate.gain.linearRampToValueAtTime(open?1:0, now + (open?ATT:REL)); }
Â  Â  Â  }
Â  Â  }
Â  Â  step();
Â  }

Â  function makeIR(seconds=2.6, decay=2.4){
Â  Â  const rate=audioCtx.sampleRate, len=Math.floor(rate*seconds);
Â  Â  const ir=audioCtx.createBuffer(2, len, rate);
Â  Â  for(let ch=0; ch<2; ch++){
Â  Â  Â  const v=ir.getChannelData(ch);
Â  Â  Â  for(let i=0;i<len;i++){
Â  Â  Â  Â  const t=i/len, env=Math.pow(1-t, decay);
Â  Â  Â  Â  v[i]=(Math.random()*2-1)*env*0.55;
Â  Â  Â  }
Â  Â  }
Â  Â  return ir;
Â  }

Â  /* ====== ì„¼ì„œ(ê¸°ìš¸ê¸° â†’ íŒ¨ë‹/ë³¼ë¥¨) ====== */
Â  let sensorsReady=false;
Â  const sensorTip=document.getElementById('sensorTip');

Â  async function requestMotionPermissions(){
Â  Â  // iOSì—ì„œëŠ” ì‚¬ìš©ì ì œìŠ¤ì²˜ ì½œìŠ¤íƒ ë‚´ì—ì„œ ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œë˜ì–´ì•¼ íŒì—…ì´ ëœ¸
Â  Â  try{
Â  Â  Â  if(typeof DeviceOrientationEvent!=='undefined' && typeof DeviceOrientationEvent.requestPermission==='function'){
Â  Â  Â  Â  DeviceOrientationEvent.requestPermission().then((r)=>{ if(r==='granted') sensorsReady=true; }).catch(()=>{});
Â  Â  Â  }else{ sensorsReady=true; }
Â  Â  }catch(e){}
Â  Â  try{
Â  Â  Â  if(typeof DeviceMotionEvent!=='undefined' && typeof DeviceMotionEvent.requestPermission==='function'){
Â  Â  Â  Â  DeviceMotionEvent.requestPermission().then((r)=>{ if(r==='granted') sensorsReady=true; }).catch(()=>{});
Â  Â  Â  }
Â  Â  }catch(e){}
Â  Â  setTimeout(()=>{ sensorTip.style.display = sensorsReady? 'none':'block'; }, 300);
Â  Â  return sensorsReady;
Â  }

Â  let latestOri={beta:0,gamma:0}, smVol=VOL_BASE, smPan=0;

Â  function getScreenAngle(){
Â  Â  const o=(screen.orientation&&screen.orientation.angle)??window.orientation??0;
Â  Â  return (typeof o==='number')?o:0;
Â  }
Â  function mapOrientation(beta,gamma){
Â  Â  const ang=((getScreenAngle()%360)+360)%360;
Â  Â  let volTilt=0, panTilt=0;
Â  Â  if(ang===0){volTilt=beta; panTilt=gamma;}
Â  Â  else if(ang===90){volTilt=-gamma; panTilt=beta;}
Â  Â  else if(ang===180){volTilt=-beta; panTilt=-gamma;}
Â  Â  else if(ang===270){volTilt=gamma; panTilt=-beta;}
Â  Â  return {volTilt, panTilt};
Â  }
Â  function tiltToPan(panTilt){
Â  Â  const t=Math.min(PAN_LIMIT_DEG, Math.max(-PAN_LIMIT_DEG, panTilt||0));
Â  Â  if(Math.abs(t)<DEADZONE_PAN_DEG) return 0;
Â  Â  return t/PAN_LIMIT_DEG;
Â  }
Â  function tiltToVol(volTilt){
Â  Â  const t=Math.min(VOL_TILT_LIMIT, Math.max(-VOL_TILT_LIMIT, volTilt||0));
Â  Â  const a=Math.max(0, Math.abs(t)-DEADZONE_VOL_DEG)/(VOL_TILT_LIMIT-DEADZONE_VOL_DEG);
Â  Â  return VOL_BASE + VOL_MAX_ADD*a;
Â  }
Â  function smoothStep(t,c,a=CTRL_SMOOTH_ALPHA){ return c+(t-c)*a; }

Â  function applyPanVol(pan, vol){
Â  Â  if(!audioCtx) return;
Â  Â  if(panSetter){ try{ panSetter(pan); }catch{} }
Â  Â  if(motionGain){
Â  Â  Â  const now=audioCtx.currentTime;
Â  Â  Â  try{ motionGain.gain.setTargetAtTime(vol, now, SMOOTH_TC); }
Â  Â  Â  catch{ motionGain.gain.cancelScheduledValues(now); motionGain.gain.linearRampToValueAtTime(vol, now+0.08); }
Â  Â  }
Â  }

Â  function initOrientationListener(){
Â  Â  if(typeof DeviceOrientationEvent==='undefined') return;
Â  Â  window.addEventListener('deviceorientation',(e)=>{
Â  Â  Â  latestOri.beta=e.beta??0; latestOri.gamma=e.gamma??0;
Â  Â  },{passive:true});
Â  }

Â  function controlLoop(){
Â  Â  requestAnimationFrame(controlLoop);
Â  Â  let pan=0, vol=VOL_BASE;
Â  Â  if(sensorsReady){
Â  Â  Â  const {volTilt, panTilt}=mapOrientation(latestOri.beta, latestOri.gamma);
Â  Â  Â  vol=smoothStep(tiltToVol(volTilt), smVol);
Â  Â  Â  pan=smoothStep(tiltToPan(panTilt), smPan);
Â  Â  Â  smVol=vol; smPan=pan;
Â  Â  }else{
Â  Â  Â  vol=smoothStep(VOL_BASE, smVol); pan=smoothStep(0, smPan);
Â  Â  Â  smVol=vol; smPan=pan;
Â  Â  }
Â  Â  applyPanVol(pan, vol);
Â  }

Â  /* ================================================= */
Â  /* ====== ì˜ì‚¬ ì˜ìƒ ì œì–´ ë¡œì§ (WebRTC & WebSocket) ====== */
Â  /* ================================================= */

Â  const projectionVideo = document.getElementById('projectionVideo');
Â  // ğŸš¨ ì´ ì£¼ì†Œë¥¼ ë‹¹ì‹ ì˜ WebSocket ì„œë²„ ì£¼ì†Œë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤!
Â  const WS_SERVER_URL = "ws://[ë‹¹ì‹ ì˜ ì„œë²„ IP ì£¼ì†Œ]:[WebSocket í¬íŠ¸]"; 
Â  // ì˜ˆì‹œ: "ws://192.168.1.100:8080" 

Â  function initWebRTC() {
Â  Â  // TODO: WebRTC PeerConnection ê°ì²´ë¥¼ ìƒì„±í•˜ê³ , Signaling ì„œë²„ì™€ ì—°ê²°í•˜ì—¬ SDP/ICE êµí™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
Â  Â  // ì´ í•¨ìˆ˜ ë‚´ì—ì„œ ì„œë²„ë¡œë¶€í„° ìŠ¤íŠ¸ë¦¼ì„ ë°›ì•„ `projectionVideo.srcObject = remoteStream;` ì½”ë“œë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
Â  Â  console.log("WebRTC ì—°ê²° ì´ˆê¸°í™” ì¤€ë¹„ ì™„ë£Œ. ì„œë²„ ì„¤ì • í›„ ì½”ë“œë¥¼ ì™„ì„±í•˜ì„¸ìš”.");
Â  Â  
Â  Â  // ì„ì‹œ: WebRTC ì—°ê²°ì´ ì„±ê³µí–ˆë‹¤ê³  ê°€ì •í•˜ê³  ì˜ìƒ í‘œì‹œ (ì‹¤ì œ ìŠ¤íŠ¸ë¦¼ì€ ì—°ê²° í›„ ì¬ìƒë¨)
Â  Â  projectionVideo.style.opacity = '0'; // WebRTC ì—°ê²° ì‹¤íŒ¨ ëŒ€ë¹„ ì´ˆê¸° ìƒíƒœ ìœ ì§€
Â  }

Â  function initProjectionControl() {
Â  Â  // 1. WebRTC ì—°ê²° ì´ˆê¸°í™” (ìŠ¤íŠ¸ë¦¼ì„ ë°›ì„ ì¤€ë¹„)
Â  Â  initWebRTC();

Â  Â  // 2. WebSocket ì—°ê²° ë° ì œì–´ ì‹ í˜¸ ìˆ˜ì‹ 
Â  Â  try {
Â  Â  Â  const ws = new WebSocket(WS_SERVER_URL);
Â  Â  Â  
Â  Â  Â  ws.onopen = () => {
Â  Â  Â  Â  console.log("WebSocket ì—°ê²° ì„±ê³µ: ì˜ì‚¬ ì œì–´ ì¤€ë¹„ ì™„ë£Œ.");
Â  Â  Â  };

Â  Â  Â  ws.onmessage = (event) => {
Â  Â  Â  Â  const message = event.data;
Â  Â  Â  Â  console.log("ì œì–´ ì‹ í˜¸ ìˆ˜ì‹ :", message);
Â  Â  Â  Â  
Â  Â  Â  Â  // ì‹ í˜¸ì— ë”°ë¥¸ ì˜ìƒ ê°€ì‹œì„± ì œì–´ (í˜ì´ë“œ ì¸/ì•„ì›ƒ)
Â  Â  Â  Â  if (message === 'PROJECTION_ON') {
Â  Â  Â  Â  Â  projectionVideo.style.opacity = '1';
Â  Â  Â  Â  } else if (message === 'PROJECTION_OFF') {
Â  Â  Â  Â  Â  projectionVideo.style.opacity = '0';
Â  Â  Â  Â  }
Â  Â  Â  };

Â  Â  Â  ws.onerror = (error) => { console.error("WebSocket ì˜¤ë¥˜ ë°œìƒ:", error); };
Â  Â  Â  ws.onclose = () => { console.warn("WebSocket ì—°ê²° ì¢…ë£Œë¨."); };

Â  Â  } catch (e) {
Â  Â  Â  console.error("WebSocket ì—°ê²° ì‹¤íŒ¨. ì„œë²„ ì£¼ì†Œë¥¼ í™•ì¸í•˜ì„¸ìš”.", e);
Â  Â  }
Â  }


Â  /* ====== ì˜¤ë²„ë ˆì´/ê¶Œí•œ íŠ¸ë¦¬ê±° (initProjectionControl í˜¸ì¶œ ì¶”ê°€ë¨) ====== */
Â  const overlay=document.getElementById('overlay');
Â  const overlayContent=document.getElementById('overlayContent');
Â  const welcomeBtn=document.getElementById('welcomeBtn');

Â  welcomeBtn.addEventListener('click', ()=>{
Â  Â  // HTTPS í•„ìˆ˜
Â  Â  if(!window.isSecureContext){
Â  Â  Â  overlayContent.innerHTML = '<div class="lineWrap"><span class="line">ì´ í˜ì´ì§€ëŠ” ë³´ì•ˆ ì—°ê²°(HTTPS)ì—ì„œë§Œ ì¹´ë©”ë¼/ë§ˆì´í¬ê°€ ë™ì‘í•©ë‹ˆë‹¤.\\nHTTPSë¡œ ì ‘ì†í•´ ì£¼ì„¸ìš”.</span></div>';
Â  Â  Â  return;
Â  Â  }

Â  Â  // 1) ì„¼ì„œ ê¶Œí•œ(ì œì¼ ë¨¼ì €, await ì—†ì´)
Â  Â  requestMotionPermissions();

Â  Â  // 2) ì˜¤ë””ì˜¤ ì´ˆê¸°í™” ë° ë§ˆì´í¬ ì‹œì‘(ì œìŠ¤ì²˜ ì½œìŠ¤íƒ ìœ ì§€)
Â  Â  initAudio();
Â  Â  if(audioCtx && audioCtx.state==='suspended'){ audioCtx.resume().catch(()=>{}); }
Â  Â  startMic().catch(()=>{});

Â  Â  initOrientationListener();
Â  Â  controlLoop();

Â  Â  // 3) ì¹´ë©”ë¼: ì œìŠ¤ì²˜ ì½œìŠ¤íƒì—ì„œ ì¦‰ì‹œ ìš”ì²­
Â  Â  attachCamera().then(()=>{
Â  Â  Â  ensureLoop();
Â  Â  Â  overlayContent.classList.add('hidden');
Â  Â  Â  setTimeout(()=>{ overlay.style.display='none'; }, 450);

Â  Â  Â  // â–¼â–¼â–¼ ì˜ì‚¬ ì œì–´ ë¡œì§ ì‹œì‘! â–¼â–¼â–¼
Â  Â  Â  initProjectionControl();
Â  Â  Â  // â–²â–²â–²

Â  Â  }).catch((e)=>{
Â  Â  Â  console.warn('getUserMedia error', e);
Â  Â  Â  const msg = (e && e.name)==='NotAllowedError'
Â  Â  Â  Â  ? 'ì¹´ë©”ë¼ ì ‘ê·¼ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ì†Œì°½ì˜ aA â†’ ì›¹ì‚¬ì´íŠ¸ ì„¤ì •ì—ì„œ \"ì¹´ë©”ë¼ í—ˆìš©\"ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜,\\nì„¤ì • > Safari > ì¹´ë©”ë¼ í—ˆìš©ì„ í™•ì¸í•˜ì„¸ìš”.'
Â  Â  Â  Â  : ((e && e.name)==='NotFoundError'
Â  Â  Â  Â  Â  ? 'ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
Â  Â  Â  Â  Â  : 'ì¹´ë©”ë¼ ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
Â  Â  Â  overlayContent.innerHTML = `<div class="lineWrap"><span class="line">${msg}</span></div>`;
Â  Â  });
Â  });

})();Â 
</script>
</body>
</html>
